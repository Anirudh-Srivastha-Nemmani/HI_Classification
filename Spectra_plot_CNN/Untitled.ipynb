{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e61386-91d7-4cb2-b8ad-1f7f1b2c0f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 13:36:12.809438: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-01 13:36:12.944124: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-01 13:36:12.951826: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/anirudh/anaconda3/envs/igwn-py39/lib/python3.9/site-packages/cv2/../../lib64:/home/anirudh/anaconda3/envs/igwn-py39/bin:/home/anirudh/local/src/lib:\n",
      "2022-12-01 13:36:12.951843: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-01 13:36:12.979594: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-01 13:36:13.520565: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/anirudh/anaconda3/envs/igwn-py39/lib/python3.9/site-packages/cv2/../../lib64:/home/anirudh/anaconda3/envs/igwn-py39/bin:/home/anirudh/local/src/lib:\n",
      "2022-12-01 13:36:13.521056: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/anirudh/anaconda3/envs/igwn-py39/lib/python3.9/site-packages/cv2/../../lib64:/home/anirudh/anaconda3/envs/igwn-py39/bin:/home/anirudh/local/src/lib:\n",
      "2022-12-01 13:36:13.521064: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "import os \n",
    "from random import shuffle\n",
    "from PIL import Image\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "761126c3-7f33-49d1-88ba-484bf789316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "associated = './Associated'\n",
    "intervening = './Intervening'\n",
    "\n",
    "url_list = [associated,intervening]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d4095d9-86f2-46fe-afc9-7882884295f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in url_list:\n",
    "#     for num , image in enumerate(os.listdir(i)):\n",
    "#         if i == './Associated':\n",
    "#             os.rename(i+\"/\"+image,i+\"/\"+\"Associated_\"+str(num)+\".png\")\n",
    "#         else:\n",
    "#             os.rename(i+\"/\"+image,i+\"/\"+\"Intervening_\"+str(num)+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37eb2c83-1b83-4236-a750-48b2383bb9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def label_img(img):\n",
    "    word_label = img.split('_')[0]\n",
    "    if word_label == \"Associated\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a5c0538-6c6d-4809-86fe-5342a634141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_associated_set(): \n",
    "    associated_data = []\n",
    "    DIR_ass = './Associated'\n",
    "    for image in tqdm(os.listdir(DIR_ass)):\n",
    "        label = label_img(image)\n",
    "        #print(image)\n",
    "        path  = os.path.join(DIR_ass,image)\n",
    "        #print(path)\n",
    "        if path in [\"./Associated/.ipynb_checkpoints\", \"./Intervening/.ipynb_checkpoints\"]:\n",
    "            pass      \n",
    "        else:\n",
    "            image = cv2.resize(cv2.imread(path),(IMG_SIZE,IMG_SIZE))\n",
    "            associated_data.append([ np.array(image),np.array(label)])\n",
    "    shuffle(associated_data)\n",
    "    np.save('associated_data.npy',associated_data)\n",
    "    return associated_data\n",
    "\n",
    "def create_intervening_set():\n",
    "    intervening_data = []\n",
    "    DIR_int = './Intervening'\n",
    "    for image in tqdm(os.listdir(DIR_int)):\n",
    "        label = label_img(image)\n",
    "        #print(image)\n",
    "        path  = os.path.join(DIR_int,image)\n",
    "        #print(path)\n",
    "        if path in [\"./Associated/.ipynb_checkpoints\", \"./Intervening/.ipynb_checkpoints\"]:\n",
    "            pass\n",
    "        else:\n",
    "            image = cv2.resize(cv2.imread(path),(IMG_SIZE,IMG_SIZE))\n",
    "            intervening_data.append([ np.array(image),np.array(label)])\n",
    "    np.save('intervening_data.npy',intervening_data)\n",
    "    return intervening_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3d53d71-518e-4768-acb8-46f934b93308",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 145.66it/s]\n",
      "/home/anirudh/anaconda3/envs/igwn-py39/lib/python3.9/site-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 267.58it/s]\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "learning_rate = 1e-3\n",
    "N_EPOCH = 5\n",
    "\n",
    "MODEL_NAME = \"associated-vs-intervening-{}-{}-{}.model\".format(learning_rate,'1DConv',N_EPOCH)\n",
    "\n",
    "associated_list = create_associated_set()\n",
    "intervening_list = create_intervening_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19eebc41-455d-41ee-98f5-95224cd274c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirudh/anaconda3/envs/igwn-py39/lib/python3.9/site-packages/numpy/core/shape_base.py:121: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ary = asanyarray(ary)\n"
     ]
    }
   ],
   "source": [
    "data = np.vstack((associated_list, intervening_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4d67ef-08dc-4088-b7f9-e2adf7a18a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2ae38d5-21e3-4dd1-af5f-fb4af474d88b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "\tverbose, epochs, batch_size = 0, 10, 32\n",
    "\t# n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=trainX.shape))\n",
    "\tmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(MaxPooling1D(pool_size=2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu'))\n",
    "\tmodel.add(Dense(1, activation='softmax'))\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t# fit network\n",
    "\tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\t# evaluate model\n",
    "\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "\treturn accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a16d91b-ae90-4c9e-807f-09dd552c2285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(scores):\n",
    "\tprint(scores)\n",
    "\tm, s = mean(scores), std(scores)\n",
    "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c14be04c-a696-4f79-ab44-9a9ac907b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def load_dataset(prefix=''):\n",
    "    # load all train\n",
    "    \n",
    "    x = data[:, 0]\n",
    "    y = data[:, 1]\n",
    "    \n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1)\n",
    "    print(y_train)\n",
    "    # one hot encode y\n",
    "    # y_train = to_categorical(y_train)\n",
    "    # y_test = to_categorical(y_test)\n",
    "    print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fe7d13f-06b8-4f31-92f6-46688a45834e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(1) array(1) array(1) array(1) array(1) array(1) array(1) array(1)\n",
      " array(0) array(0) array(0) array(1) array(0) array(1) array(1) array(1)\n",
      " array(1) array(1) array(1) array(1) array(1) array(0) array(1) array(1)\n",
      " array(1) array(0) array(1) array(1) array(1) array(1) array(0) array(1)\n",
      " array(0) array(1) array(1) array(1) array(0) array(0) array(1) array(1)\n",
      " array(1) array(0) array(1) array(1) array(1) array(1) array(1) array(1)\n",
      " array(0) array(1) array(1) array(1) array(1) array(0) array(1) array(0)\n",
      " array(1) array(1) array(1) array(1) array(1) array(1) array(1) array(1)\n",
      " array(1) array(1) array(1) array(0) array(1) array(1) array(1) array(1)\n",
      " array(1) array(1) array(1) array(1) array(1) array(1) array(1) array(1)\n",
      " array(1) array(0) array(0) array(1) array(1) array(1) array(1) array(1)\n",
      " array(1) array(1) array(1) array(1) array(1) array(1) array(1) array(0)\n",
      " array(1) array(1) array(1) array(1) array(1) array(0) array(1) array(1)\n",
      " array(0) array(1) array(1) array(1) array(0) array(1) array(1)]\n",
      "(111,) (111,) (13,) (13,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"conv1d_2\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (None, 111)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \tsummarize_results(scores)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# run the experiment\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(repeats)\u001b[0m\n\u001b[1;32m      5\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(repeats):\n\u001b[0;32m----> 7\u001b[0m \tscore \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtesty\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \tscore \u001b[38;5;241m=\u001b[39m score \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100.0\u001b[39m\n\u001b[1;32m      9\u001b[0m \t\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>#\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (r\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, score))\n",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(trainX, trainy, testX, testy)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mConv1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv1D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dropout(\u001b[38;5;241m0.5\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/igwn-py39/lib/python3.9/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/igwn-py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/igwn-py39/lib/python3.9/site-packages/keras/engine/input_spec.py:250\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    248\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ndim \u001b[38;5;241m<\u001b[39m spec\u001b[38;5;241m.\u001b[39mmin_ndim:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    251\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    252\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected min_ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mmin_ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    254\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    255\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m         )\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# Check dtype.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"conv1d_2\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (None, 111)"
     ]
    }
   ],
   "source": [
    "def run_experiment(repeats=10):\n",
    "\t# load data\n",
    "\ttrainX, trainy, testX, testy = load_dataset()\n",
    "\t# repeat experiment\n",
    "\tscores = list()\n",
    "\tfor r in range(repeats):\n",
    "\t\tscore = evaluate_model(trainX, trainy, testX, testy)\n",
    "\t\tscore = score * 100.0\n",
    "\t\tprint('>#%d: %.3f' % (r+1, score))\n",
    "\t\tscores.append(score)\n",
    "\t# summarize results\n",
    "\tsummarize_results(scores)\n",
    "\n",
    "# run the experiment\n",
    "run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27acd90-3ec0-4f72-8ef8-a18fbd92e669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
